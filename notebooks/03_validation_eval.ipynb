{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c442ec-6ea7-4654-8b94-3f25ca8f82c7",
   "metadata": {},
   "source": [
    "# ðŸ§ª DocScribe â€” 03 Â· Validation & Grounding\n",
    "\n",
    "**Purpose:**\n",
    "Evaluate the clinical note extractor and ensure each component (chief complaint, assessment, diagnosis, orders, plan, follow-up) works as expected.\n",
    "\n",
    "**Key steps:**\n",
    "1. Load fallback regex extractor (works offline)\n",
    "2. Create evaluation dataset with gold labels\n",
    "3. Compute F1 and semantic similarity\n",
    "4. Print detailed metrics and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ee82ce-974a-49b9-bcb8-098e8655791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json, time, sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from rapidfuzz.fuzz import partial_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d049ec6-ca9c-4927-bebb-e8b9e3ab26d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Patched extractor loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- PATCH: stronger regex extractor for 03_validation_eval.ipynb ---\n",
    "from pathlib import Path\n",
    "import sys, re, json\n",
    "ROOT = Path(\"..\").resolve()\n",
    "SRC  = ROOT / \"src\"\n",
    "SRC.mkdir(exist_ok=True)\n",
    "(SRC / \"__init__.py\").write_text(\"\", encoding=\"utf-8\")\n",
    "\n",
    "extract_py = r'''\n",
    "from __future__ import annotations\n",
    "import re, json\n",
    "from typing import List, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ClinicalNote(BaseModel):\n",
    "    chief_complaint: str = Field(default=\"\")\n",
    "    assessment: str = Field(default=\"\")\n",
    "    diagnosis: List[str] = Field(default_factory=list)\n",
    "    orders: List[str] = Field(default_factory=list)\n",
    "    plan: List[str] = Field(default_factory=list)\n",
    "    follow_up: str = Field(default=\"\")\n",
    "\n",
    "SENT_SPLIT = re.compile(r\"(?<=[.!?])\\s+\")\n",
    "NONWORD    = re.compile(r\"\\s+\")\n",
    "LOWERPAST  = re.compile(r\"\\b(ordered|prescribed|given|advised|began)\\b\", re.I)\n",
    "\n",
    "HEURISTICS = {\n",
    "    \"imaging\": r\"\\b(x-?ray|cxr|ct|mri|ultra\\s*sound|ultrasound|ekg|ecg|echo|xr)\\b\",\n",
    "    \"labs\":    r\"\\b(cbc|cmp|a1c|bmp|ua|urinalysis|culture|strep(?:\\s*test)?)\\b\"\n",
    "}\n",
    "\n",
    "MED_RX  = re.compile(r\"\\b([A-Z][a-zA-Z]+(?:\\s[A-Za-z][a-zA-Z]+)*\\s\\d+\\s?mg(?:\\s(?:BID|TID|daily|q\\d+h|x\\d+))?)\\b\")\n",
    "PLAN_RX = re.compile(r\"\\b(start|begin|give|prescribe|advise|recommend)\\b([^.;]{1,120})\", re.I)\n",
    "ORD_RX  = re.compile(r\"\\b(order|ordered)\\b([^.;]{1,160})\", re.I)\n",
    "\n",
    "def _sentences(txt: str) -> List[str]:\n",
    "    txt = (txt or \"\").strip()\n",
    "    if not txt:\n",
    "        return []\n",
    "    parts = SENT_SPLIT.split(txt)\n",
    "    return [p.strip() for p in parts if p.strip()]\n",
    "\n",
    "def _pick_chief_complaint(sents: List[str]) -> str:\n",
    "    if not sents:\n",
    "        return \"\"\n",
    "    cc = sents[0]\n",
    "    # trim durations like \"for 3 days\" at the tail for neatness\n",
    "    cc = re.sub(r\"\\bfor\\s+\\d+\\s+(?:day|days|wk|week|weeks)\\b\\.?$\", \"\", cc, flags=re.I).strip()\n",
    "    # prefer short symptom-like sentence if first is long\n",
    "    if len(cc) > 120 and len(sents) > 1:\n",
    "        return sents[1][:120]\n",
    "    return cc[:160]\n",
    "\n",
    "def _pick_assessment(text: str, sents: List[str]) -> str:\n",
    "    # look for explicit markers\n",
    "    m = re.search(r\"\\b(assessment\\s*:)\\s*([^.;]{1,160})\", text, flags=re.I)\n",
    "    if m:\n",
    "        return NONWORD.sub(\" \", m.group(2)).strip().rstrip(\".\")\n",
    "    # otherwise find sentence with likely/suspect/impression\n",
    "    for s in sents:\n",
    "        if re.search(r\"\\b(likely|suspect|impression)\\b\", s, flags=re.I):\n",
    "            return NONWORD.sub(\" \", s).strip().rstrip(\".\")\n",
    "    return \"\"\n",
    "\n",
    "def _diagnosis_from_assessment(assessment: str) -> List[str]:\n",
    "    if not assessment:\n",
    "        return []\n",
    "    # take trailing 6 words as a soft proxy for the condition\n",
    "    tail = \" \".join(assessment.split()[-8:])\n",
    "    tail = tail.strip().strip(\".\")\n",
    "    # drop bare markers\n",
    "    if tail.lower() in {\"likely\", \"suspect\", \"impression\"}:\n",
    "        return []\n",
    "    return [tail] if tail else []\n",
    "\n",
    "def _expand_imaging_labs(text: str) -> List[str]:\n",
    "    out = []\n",
    "    for patt in (HEURISTICS[\"imaging\"], HEURISTICS[\"labs\"]):\n",
    "        for m in re.finditer(patt, text, flags=re.I):\n",
    "            span = m.group(0)\n",
    "            # try to capture an anatomical word just before (e.g., 'chest X-ray', 'ankle x-ray')\n",
    "            start = max(0, m.start()-25)\n",
    "            window = text[start:m.start()]\n",
    "            pre = \"\"\n",
    "            pm = re.search(r\"(\\b\\w+\\b)\\s*$\", window)\n",
    "            if pm:\n",
    "                pre = pm.group(1) + \" \"\n",
    "            out.append((pre + span).strip())\n",
    "    return out\n",
    "\n",
    "def _split_list_phrase(phrase: str) -> List[str]:\n",
    "    # split on \",\", \" and \", \" & \"\n",
    "    parts = re.split(r\",|\\band\\b|&\", phrase, flags=re.I)\n",
    "    parts = [NONWORD.sub(\" \", p).strip() for p in parts]\n",
    "    return [p for p in parts if p]\n",
    "\n",
    "def _clean_dedup(items: List[str]) -> List[str]:\n",
    "    seen = set(); out = []\n",
    "    for it in items:\n",
    "        it = NONWORD.sub(\" \", it).strip().rstrip(\".\")\n",
    "        if not it:\n",
    "            continue\n",
    "        low = it.lower()\n",
    "        if low in seen:\n",
    "            continue\n",
    "        seen.add(low)\n",
    "        out.append(it)\n",
    "    return out\n",
    "\n",
    "def _extract_followup(text: str) -> str:\n",
    "    m = re.search(r\"\\b(follow\\s*-?\\s*up[^.]{0,80}|return[^.]{0,80}|re-?\\s*evaluate[^.]{0,80})\", text, flags=re.I)\n",
    "    if not m:\n",
    "        return \"\"\n",
    "    fu = m.group(0)\n",
    "    # normalize x5 day -> x5 days\n",
    "    fu = re.sub(r\"\\bx(\\d+)\\s*day\\b\", r\"x\\1 days\", fu, flags=re.I)\n",
    "    return NONWORD.sub(\" \", fu).strip().rstrip(\".\")\n",
    "\n",
    "def _regex_extract(transcript: str) -> Dict[str, Any]:\n",
    "    text = (transcript or \"\").strip()\n",
    "    sents = _sentences(text)\n",
    "    data = {\"chief_complaint\":\"\", \"assessment\":\"\", \"diagnosis\":[], \"orders\":[], \"plan\":[], \"follow_up\":\"\"}\n",
    "\n",
    "    # Chief complaint\n",
    "    data[\"chief_complaint\"] = _pick_chief_complaint(sents)\n",
    "\n",
    "    # Assessment & diagnosis\n",
    "    data[\"assessment\"] = _pick_assessment(text, sents)\n",
    "    data[\"diagnosis\"]  = _diagnosis_from_assessment(data[\"assessment\"])\n",
    "\n",
    "    # Orders from keywords and 'order...' phrases\n",
    "    orders = _expand_imaging_labs(text)\n",
    "    for m in ORD_RX.finditer(text):\n",
    "        phrase = m.group(2)\n",
    "        orders.extend(_split_list_phrase(phrase))\n",
    "    # Medications count both as orders & generate plan entries\n",
    "    meds = []\n",
    "    for m in MED_RX.finditer(text):\n",
    "        meds.append(m.group(1))\n",
    "    orders.extend(meds)\n",
    "\n",
    "    # Plan from plan-verbs and explicit supportive words like RICE/ibuprofen (without dose)\n",
    "    plans = []\n",
    "    for m in PLAN_RX.finditer(text):\n",
    "        plans.extend(_split_list_phrase(m.group(2)))\n",
    "    # common conservative care tokens\n",
    "    if re.search(r\"\\bRICE\\b\", text):\n",
    "        plans.append(\"RICE\")\n",
    "    if re.search(r\"\\bibuprofen\\b(?![^.]*mg)\", text, flags=re.I):\n",
    "        plans.append(\"ibuprofen\")\n",
    "\n",
    "    # If a med with dose was seen, add 'start <med>' to plan\n",
    "    for med in meds:\n",
    "        plans.append(f\"start {med}\")\n",
    "\n",
    "    # Follow-up\n",
    "    data[\"follow_up\"] = _extract_followup(text)\n",
    "\n",
    "    # Clean + de-dup\n",
    "    data[\"orders\"] = _clean_dedup(orders)\n",
    "    data[\"plan\"]   = _clean_dedup(plans)\n",
    "    data[\"diagnosis\"] = _clean_dedup(data[\"diagnosis\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_note(transcript: str):\n",
    "    data = _regex_extract(transcript)\n",
    "    note = ClinicalNote(**data)\n",
    "    # raw output (for this regex version) = transcript itself, to keep interface stable\n",
    "    return note, transcript\n",
    "'''\n",
    "\n",
    "(SRC / \"extract_clinical.py\").write_text(extract_py, encoding=\"utf-8\")\n",
    "\n",
    "# keep your existing composer\n",
    "compose_py = r'''\n",
    "from typing import Tuple\n",
    "from .extract_clinical import ClinicalNote\n",
    "\n",
    "def compose_note(note: ClinicalNote) -> Tuple[str, str]:\n",
    "    s = note.chief_complaint or \"â€”\"\n",
    "    o = \", \".join(note.orders) if note.orders else \"â€”\"\n",
    "    a = note.assessment or (\", \".join(note.diagnosis) if note.diagnosis else \"â€”\")\n",
    "    p = \"; \".join(note.plan) if note.plan else \"â€”\"\n",
    "    f = note.follow_up or \"â€”\"\n",
    "    soap = f\"S: {s}\\nO: {o}\\nA: {a}\\nP: {p}\\nFollow-up: {f}\\n\"\n",
    "    summary = f\"Visit summary: {s}. Assessment: {a}. Plan: {p}. Follow-up: {f}.\"\n",
    "    return soap, summary\n",
    "'''\n",
    "(SRC / \"compose_note.py\").write_text(compose_py, encoding=\"utf-8\")\n",
    "\n",
    "# reload\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "from importlib import reload\n",
    "import src.extract_clinical as _ec\n",
    "reload(_ec)\n",
    "from src.extract_clinical import extract_note\n",
    "from src.compose_note import compose_note\n",
    "\n",
    "print(\"âœ… Patched extractor loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8642a93b-ea99-43a9-a446-5f654ff41ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Eval file recreated at: /Users/saturnine/DocScribe/eval/eval_transcripts.jsonl\n"
     ]
    }
   ],
   "source": [
    "EVAL_PATH = ROOT / \"eval\" / \"eval_transcripts.jsonl\"\n",
    "EVAL_PATH.parent.mkdir(exist_ok=True)\n",
    "\n",
    "DEMO_EVAL = [\n",
    "    {\n",
    "        \"text\": \"Fever and cough for 3 days. Mild shortness of breath. Likely CAP. \"\n",
    "                \"Order chest X-ray and start azithromycin 500 mg daily x5. Follow up in 2 days.\",\n",
    "        \"gold\": {\n",
    "            \"chief_complaint\": \"Fever and cough\",\n",
    "            \"assessment\": \"Likely CAP\",\n",
    "            \"diagnosis\": [],\n",
    "            \"orders\": [\"chest X-ray\", \"azithromycin 500 mg daily x5\"],\n",
    "            \"plan\": [\"azithromycin 500 mg daily x5\"],\n",
    "            \"follow_up\": \"2 days\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Left ankle pain after inversion injury yesterday. Likely lateral ankle sprain. \"\n",
    "                \"X-ray ankle to rule out fracture. RICE and ibuprofen 400 mg PRN.\",\n",
    "        \"gold\": {\n",
    "            \"chief_complaint\": \"left ankle pain\",\n",
    "            \"assessment\": \"Likely lateral ankle sprain\",\n",
    "            \"diagnosis\": [],\n",
    "            \"orders\": [\"X-ray ankle\"],\n",
    "            \"plan\": [\"RICE\", \"ibuprofen 400 mg PRN\"],\n",
    "            \"follow_up\": \"\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Dysuria and urinary frequency for 2 days. No fever or flank pain. \"\n",
    "                \"Likely uncomplicated UTI. Urinalysis and nitrofurantoin 100 mg BID x5 days.\",\n",
    "        \"gold\": {\n",
    "            \"chief_complaint\": \"Dysuria\",\n",
    "            \"assessment\": \"Likely uncomplicated UTI\",\n",
    "            \"diagnosis\": [],\n",
    "            \"orders\": [\"Urinalysis\", \"nitrofurantoin 100 mg BID x5 days\"],\n",
    "            \"plan\": [\"nitrofurantoin 100 mg BID x5 days\"],\n",
    "            \"follow_up\": \"2 days\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Overwrite eval file\n",
    "with EVAL_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for row in DEMO_EVAL:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"âœ… Eval file recreated at:\", EVAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a633523-40d8-4e85-949a-f0d3b68a3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_NORM = re.compile(r\"\\s+\")\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return WORD_NORM.sub(\" \", (s or \"\").strip().lower().rstrip(\".\"))\n",
    "\n",
    "def f1_for_lists(pred: List[str], gold: List[str], loose=True):\n",
    "    P = [x for x in (pred or []) if x]\n",
    "    G = [x for x in (gold or []) if x]\n",
    "    if not P and not G: return (1,1,1)\n",
    "    if not P: return (0,0,0)\n",
    "    if not G: return (0,1,0)\n",
    "    used = set(); tp=0\n",
    "    for p in P:\n",
    "        best, jbest = -1, -1\n",
    "        for j,g in enumerate(G):\n",
    "            if j in used: continue\n",
    "            score = partial_ratio(p,g) if loose else (100 if norm(p)==norm(g) else 0)\n",
    "            if score>best: best, jbest = score, j\n",
    "        if best>=90: tp+=1; used.add(jbest)\n",
    "    fp = len(P)-tp; fn = len(G)-tp\n",
    "    prec = tp/(tp+fp) if tp+fp else 0\n",
    "    rec = tp/(tp+fn) if tp+fn else 0\n",
    "    f1 = 2*prec*rec/(prec+rec) if prec+rec else 0\n",
    "    return round(prec,3), round(rec,3), round(f1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccff81d4-eb66-49ea-a42a-7eec14633424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Completed evaluation on 3 examples.\n"
     ]
    }
   ],
   "source": [
    "rows = [json.loads(l) for l in EVAL_PATH.read_text().splitlines()]\n",
    "results = []\n",
    "\n",
    "for ex in rows:\n",
    "    if \"gold\" not in ex:\n",
    "        continue\n",
    "\n",
    "    text = ex[\"text\"]\n",
    "    gold = ex[\"gold\"]\n",
    "\n",
    "    t0 = time.time()\n",
    "    note, _ = extract_note(text)\n",
    "    latency = round(time.time()-t0,2)\n",
    "    pred = note.dict()\n",
    "\n",
    "    cc_sim = partial_ratio(pred[\"chief_complaint\"], gold[\"chief_complaint\"])\n",
    "    as_sim = partial_ratio(pred[\"assessment\"], gold[\"assessment\"])\n",
    "    fu_sim = partial_ratio(pred[\"follow_up\"], gold[\"follow_up\"])\n",
    "    diag_f = f1_for_lists(pred[\"diagnosis\"], gold[\"diagnosis\"])[2]\n",
    "    ord_f  = f1_for_lists(pred[\"orders\"], gold[\"orders\"])[2]\n",
    "    plan_f = f1_for_lists(pred[\"plan\"], gold[\"plan\"])[2]\n",
    "\n",
    "    results.append({\n",
    "        \"cc\": cc_sim, \"as\": as_sim, \"fu\": fu_sim,\n",
    "        \"diag\": diag_f, \"ord\": ord_f, \"plan\": plan_f,\n",
    "        \"lat\": latency\n",
    "    })\n",
    "\n",
    "print(\"âœ… Completed evaluation on\", len(results), \"examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdf9acb-b264-4035-86e6-ac245e67b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MEAN METRICS ===\n",
      "Chief Complaint: 97.778\n",
      "Assessment     : 100.0\n",
      "Follow-up      : 66.667\n",
      "Diagnosis F1   : 0.0\n",
      "Orders F1      : 0.722\n",
      "Plan F1        : 0.5\n",
      "Latency (s)    : 0.0\n",
      "\n",
      "=== PER-SAMPLE ===\n",
      "01 | CC:100.0  A:100.0  FU:100.0  ORD:1.00  PLAN:1.00  LAT:0.00\n",
      "02 | CC:93.33333333333333  A:100.0  FU:100.0  ORD:0.67  PLAN:0.50  LAT:0.00\n",
      "03 | CC:100.0  A:100.0  FU:0.0  ORD:0.50  PLAN:0.00  LAT:0.00\n"
     ]
    }
   ],
   "source": [
    "def avg(xs): return round(sum(xs)/len(xs),3)\n",
    "\n",
    "print(\"\\n=== MEAN METRICS ===\")\n",
    "print(\"Chief Complaint:\", avg([r[\"cc\"] for r in results]))\n",
    "print(\"Assessment     :\", avg([r[\"as\"] for r in results]))\n",
    "print(\"Follow-up      :\", avg([r[\"fu\"] for r in results]))\n",
    "print(\"Diagnosis F1   :\", avg([r[\"diag\"] for r in results]))\n",
    "print(\"Orders F1      :\", avg([r[\"ord\"] for r in results]))\n",
    "print(\"Plan F1        :\", avg([r[\"plan\"] for r in results]))\n",
    "print(\"Latency (s)    :\", avg([r[\"lat\"] for r in results]))\n",
    "\n",
    "print(\"\\n=== PER-SAMPLE ===\")\n",
    "for i,r in enumerate(results,1):\n",
    "    print(f\"{i:02d} | CC:{r['cc']:>3}  A:{r['as']:>3}  FU:{r['fu']:>3}  ORD:{r['ord']:.2f}  PLAN:{r['plan']:.2f}  LAT:{r['lat']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9680b0f-3c90-4c7b-bc58-38aaf0238e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Case 1 ===\n",
      "TRANSCRIPT: Fever and cough for 3 days. Mild shortness of breath. Likely CAP. Order chest X-ray and start azithromycin 500 mg daily x5. Follow up in 2 days.\n",
      "PREDICTED JSON:\n",
      "{\n",
      "  \"chief_complaint\": \"Fever and cough\",\n",
      "  \"assessment\": \"Likely CAP\",\n",
      "  \"diagnosis\": [\n",
      "    \"Likely CAP\"\n",
      "  ],\n",
      "  \"orders\": [\n",
      "    \"chest X-ray\",\n",
      "    \"start azithromycin 500 mg daily x5\"\n",
      "  ],\n",
      "  \"plan\": [\n",
      "    \"azithromycin 500 mg daily x5\"\n",
      "  ],\n",
      "  \"follow_up\": \"Follow up in 2 days\"\n",
      "}\n",
      "\n",
      "=== Case 2 ===\n",
      "TRANSCRIPT: Left ankle pain after inversion injury yesterday. Likely lateral ankle sprain. X-ray ankle to rule out fracture. RICE and ibuprofen 400 mg PRN.\n",
      "PREDICTED JSON:\n",
      "{\n",
      "  \"chief_complaint\": \"Left ankle pain after inversion injury yesterday.\",\n",
      "  \"assessment\": \"Likely lateral ankle sprain\",\n",
      "  \"diagnosis\": [\n",
      "    \"Likely lateral ankle sprain\"\n",
      "  ],\n",
      "  \"orders\": [\n",
      "    \"X-ray\",\n",
      "    \"RICE and ibuprofen 400 mg\"\n",
      "  ],\n",
      "  \"plan\": [\n",
      "    \"RICE\",\n",
      "    \"start RICE and ibuprofen 400 mg\"\n",
      "  ],\n",
      "  \"follow_up\": \"\"\n",
      "}\n",
      "\n",
      "=== Case 3 ===\n",
      "TRANSCRIPT: Dysuria and urinary frequency for 2 days. No fever or flank pain. Likely uncomplicated UTI. Urinalysis and nitrofurantoin 100 mg BID x5 days.\n",
      "PREDICTED JSON:\n",
      "{\n",
      "  \"chief_complaint\": \"Dysuria and urinary frequency\",\n",
      "  \"assessment\": \"Likely uncomplicated UTI\",\n",
      "  \"diagnosis\": [\n",
      "    \"Likely uncomplicated UTI\"\n",
      "  ],\n",
      "  \"orders\": [\n",
      "    \"Urinalysis\",\n",
      "    \"Urinalysis and nitrofurantoin 100 mg BID\"\n",
      "  ],\n",
      "  \"plan\": [\n",
      "    \"start Urinalysis and nitrofurantoin 100 mg BID\"\n",
      "  ],\n",
      "  \"follow_up\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i, ex in enumerate(rows,1):\n",
    "    if \"gold\" not in ex: continue\n",
    "    text = ex[\"text\"]\n",
    "    note,_ = extract_note(text)\n",
    "    pred = note.dict()\n",
    "    print(f\"\\n=== Case {i} ===\")\n",
    "    print(\"TRANSCRIPT:\", text)\n",
    "    print(\"PREDICTED JSON:\")\n",
    "    print(json.dumps(pred, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DocScribe",
   "language": "python",
   "name": "docscribe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
